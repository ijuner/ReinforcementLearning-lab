{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will explore the ReLU (Rectified Linear Unit) activation function using PyTorch. We will start with the most basic example and then provide three more examples, each time increasing the level of complexity.\n",
    "\n",
    "ReLU stands for Rectified Linear Unit. It is one of the most widely used activation functions in deep learning models. The ReLU function is defined as:\n",
    "\n",
    "$$\n",
    "ReLU(x) = max(0, x)\n",
    "$$\n",
    "\n",
    "This means that any negative input will be set to zero, while positive inputs remain unchanged.\n",
    "\n",
    "Let's start with some basic examples.\n",
    "In this example, we will apply the ReLU function to a simple tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # Import torch.nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 2.])\n"
     ]
    }
   ],
   "source": [
    "### Example 1: Basic ReLU\n",
    "# Basic tensor\n",
    "x = torch.tensor([-1.0, 0.0, 1.0, 2.0])\n",
    "# Apply ReLU\n",
    "y = F.relu(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 2.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Example #2 - 2D tensor\n",
    "x = torch.tensor([[-1.0, 2.0], [0.0, -3.0]])\n",
    "# Apply ReLU\n",
    "y = F.relu(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n",
      "tensor([[0.0000, 0.6083],\n",
      "        [1.4957, 0.7707]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example #3 - Define a simple neural network with one ReLU layer\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc = nn.Linear(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = F.relu(x)  # Apply ReLU activation\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network\n",
    "net = SimpleNN()\n",
    "print(net)\n",
    "# Example input\n",
    "x = torch.tensor([[1.0, -1.0], [0.0, 2.0]])\n",
    "# Forward pass\n",
    "y = net(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example #4 - Define a more complex neural network with multiple layers\n",
    "class ComplexNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        self.fc2 = nn.Linear(4, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network\n",
    "net = ComplexNN()\n",
    "# Example input\n",
    "x = torch.tensor([[1.0, -1.0], [0.0, 2.0]])\n",
    "# Forward pass\n",
    "y = net(x)\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
